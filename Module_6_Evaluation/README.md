##### DAE code reference: https://github.com/tagoyal/factuality-datasets

##### PARENT code reference: https://github.com/google-research/language/tree/master/language/table_text_eval

Traditional evaluation methods:

    BLEU
  
    ROUGE
  
    METEOR

Evaluation methods which are chosen with the intention to measure halucination level:

    PARENT - should be run from command line
    DAE

Run preprocess_T5_output.py for the output files which are generated by T5 verbalizers

Run preprocess_distilGPT2_output.py for the output files which are generated by DistilGPT2 verbalizers

Run extract_triples_4_PARENT.py to extract triples (3 versions: triples, triples + wiki, triples + wiki desc only)

Run calculate_BLEU_ROUGE_METEOR.py - results will be in 'results' folder

For PARENT scores:

    run table_test_eval.py from command line. remember to adjust the path to the generated text file
    record the results to the txt files which start with 'parent_results_of_' in the 'PARENT_results' folder

For DAE scores:

    run prepare_my_outputs.py - resulting files will be located in 'DAE/prepared_data' folder
    run evaluate_generated_outputs.py - results will be in 'DAE_results'
    Imported note: A few generation instances contain issues like being too shor or long. Most of the issues are gone after running prepare_my_outputs.py but a few samples are corrected manually. You may find those instances by searching 'filler filler filler filler' string.

